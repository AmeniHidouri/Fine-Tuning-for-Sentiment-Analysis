ğŸ§  Fine-Tuning dâ€™un ModÃ¨le de Sentiment avec PEFT (LoRA)

Ce projet montre comment spÃ©cialiser un modÃ¨le de langage prÃ©-entraÃ®nÃ© pour une tÃ¢che de classification de sentiment, en utilisant une approche moderne et efficace : PEFT (Parameter-Efficient Fine-Tuning) avec LoRA (Low-Rank Adaptation).
Lâ€™objectif est de fine-tuner DistilBERT sur le dataset IMDB pour dÃ©terminer si une critique de film est positive ou nÃ©gative.

ğŸš€ Contexte Technologique
ğŸ¯ Quâ€™est-ce que le Fine-Tuning ?

Le fine-tuning consiste Ã  adapter un grand modÃ¨le prÃ©-entraÃ®nÃ© (comme BERT) Ã  une tÃ¢che spÃ©cifique en continuant son entraÃ®nement sur un petit dataset spÃ©cialisÃ©. Cela permet de transfÃ©rer ses connaissances gÃ©nÃ©rales vers une compÃ©tence ciblÃ©e (ex : analyse de sentiment).

âš™ï¸ Pourquoi PEFT et LoRA ?

Fine-tuner tous les paramÃ¨tres dâ€™un modÃ¨le complet est coÃ»teux en GPU. PEFT rÃ©sout ce problÃ¨me en gelant la majoritÃ© du modÃ¨le et en nâ€™entraÃ®nant que de petites couches supplÃ©mentaires.

MÃ©thode	Avantages
PEFT (LoRA)	â¤ 0.1% de paramÃ¨tres entraÃ®nÃ©s
â¤ TrÃ¨s faible consommation GPU
â¤ ModÃ¨le plus rapide & lÃ©ger
ğŸ“¦ Installation
1ï¸âƒ£ PrÃ©requis

Python 3.8+

pip ou conda

2ï¸âƒ£ Installation du projet
# Cloner le dÃ©pÃ´t
git clone [URL_DE_VOTRE_DEPOT_GITHUB]
cd [NOM_DU_DEPOT]

# Installer les dÃ©pendances
pip install -r requirements.txt


ğŸ” Le fichier requirements.txt doit contenir :
transformers, datasets, evaluate, peft, torch

â–¶ï¸ ExÃ©cution
python fine_tune_sentiment.py

ğŸ§ª Pipeline du Script fine_tune_sentiment.py
Ã‰tape	Description
1. Chargement des donnÃ©es	Dataset IMDB via datasets
2. Initialisation du modÃ¨le	distilbert-base-uncased + Tokenizer
3. Configuration LoRA	DÃ©finition d'une LoraConfig (r, alpha, dropout)
4. Tokenisation	PrÃ©paration des critiques en entrÃ©e modÃ¨le
5. EntraÃ®nement (Trainer)	Fine-tuning des adaptateurs LoRA uniquement
6. Ã‰valuation	Calcul de la prÃ©cision (accuracy)
7. InfÃ©rence	PrÃ©dictions sur de nouvelles phrases
ğŸ“Š RÃ©sultats Attendus

AprÃ¨s entraÃ®nement, vous devriez voir :

Final evaluation results:
{'eval_loss': 0.35, 'eval_accuracy': 0.85, ...}


PrÃ©dictions exemple :

Review: "This movie was absolutely fantastic!"
Prediction: [{'label': 'POSITIVE', 'score': 0.99}]

Review: "I was really disappointed by this film."
Prediction: [{'label': 'NEGATIVE', 'score': 0.99}]

ğŸ§­ Pourquoi ce Projet est Important ?

âœ… Comprendre les mÃ©thodes modernes de fine-tuning (PEFT)
âœ… RÃ©duire les coÃ»ts GPU tout en conservant les performances
âœ… PrÃ©parer le terrain pour appliquer LoRA sur des LLMs (ChatGPT, LLaMa, Mistral)

ğŸ›¡ï¸ Licence

Ce projet est sous licence MIT â€” libre Ã  vous de le modifier et l'adapter !

ğŸ¯ PrÃªt(e) Ã  fine-tuner des LLM avec LoRA ? Ce projet est votre point de dÃ©part.
